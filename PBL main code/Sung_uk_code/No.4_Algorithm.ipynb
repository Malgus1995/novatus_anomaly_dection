{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a277f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\torch_cuda\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abea9830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5d1325",
   "metadata": {},
   "source": [
    "Feature Extraction and Extension CODE: https://github.com/min0355/ai-novatus/blob/main/PBL%20main%20code/No.3_Feature%20selection%20and%20Feature%20Extension.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92e34e2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './pre_sensor.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\Desktop\\ai-novatus-main\\ai-novatus-main\\PBL main code\\Sung_uk_code\\No.4_Algorithm.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/ai-novatus-main/ai-novatus-main/PBL%20main%20code/Sung_uk_code/No.4_Algorithm.ipynb#ch0000003?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./pre_sensor.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/ai-novatus-main/ai-novatus-main/PBL%20main%20code/Sung_uk_code/No.4_Algorithm.ipynb#ch0000003?line=1'>2</a>\u001b[0m df\u001b[39m.\u001b[39mhead(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch_cuda\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch_cuda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch_cuda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch_cuda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch_cuda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch_cuda\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './pre_sensor.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'./sensor04_pre_sensor.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187f4fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(df):\n",
    "    \n",
    "    label_mapping = {\n",
    "    0.0: 1, # normal\n",
    "    0.5: 2, # recovering\n",
    "    1: 0  # broken\n",
    "    }\n",
    "    \n",
    "    del df['Unnamed: 0']\n",
    "    df.loc[:, \"operation\"] = df.operation.map(label_mapping) \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df = df.set_index('timestamp')\n",
    "    feature = [\n",
    "    f for f in df.columns if f in (\"sensor_04\", \"operation\")\n",
    "    ]\n",
    "    return df[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e2ffdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>operation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <td>0.792242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:01:00</th>\n",
       "      <td>0.792242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:02:00</th>\n",
       "      <td>0.797904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:03:00</th>\n",
       "      <td>0.784402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:04:00</th>\n",
       "      <td>0.794855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sensor_04  operation\n",
       "timestamp                                \n",
       "2018-04-01 00:00:00   0.792242          1\n",
       "2018-04-01 00:01:00   0.792242          1\n",
       "2018-04-01 00:02:00   0.797904          1\n",
       "2018-04-01 00:03:00   0.784402          1\n",
       "2018-04-01 00:04:00   0.794855          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = make_df(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc8fb660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['operation'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adf92bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.where(df['operation'] == 0, 0, 1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74425039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220320"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713bceb2",
   "metadata": {},
   "source": [
    "## LSTM (check another kernel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59738cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_x = df[labels == 1] # normal or recovering\n",
    "anomaly_x = df[labels == 0] # broken \n",
    "\n",
    "normal_y = labels[labels == 1]\n",
    "anomaly_y = labels[labels == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d841fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220313, 2)\n",
      "(220313,)\n",
      "(7, 2)\n",
      "(7,)\n"
     ]
    }
   ],
   "source": [
    "print(normal_x.shape)\n",
    "print(normal_y.shape)\n",
    "print(anomaly_x.shape)\n",
    "print(anomaly_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d288ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_normal = len(normal_x)\n",
    "len_normal_train = int(0.8 * len_normal)\n",
    "x_train = normal_x[:len_normal_train]\n",
    "\n",
    "x_test_normal = normal_x[len_normal_train:]\n",
    "len_anomaly_test = len(x_test_normal)\n",
    "x_test_anomaly = anomaly_x[:len_anomaly_test]\n",
    "\n",
    "x_test = np.concatenate([x_test_normal, x_test_anomaly])\n",
    "y_test = np.ones(len(x_test))\n",
    "y_test[:len(x_test_normal)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b10d71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176250, 2)\n",
      "(44070, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "302441ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sensor_04    0\n",
       "operation    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[x_train['operation'] == 0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d29cb",
   "metadata": {},
   "source": [
    "### define error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d87a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(s1, s2, _rmse=True):\n",
    "    if _rmse:\n",
    "        return np.sqrt(np.mean((s1 - s2) ** 2, axis=1))\n",
    "    return np.mean((s1 - s2) ** 2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79725715",
   "metadata": {},
   "source": [
    "### the reparameterization trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b28cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(args):\n",
    "    z_mean, z_log_var =args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7e569ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "342afd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = x_train.shape[1]\n",
    "input_shape = (original_dim,)\n",
    "intermediate_dim = 2           # original_dim / 2\n",
    "latent_dim = 1                 # original_dim / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c5b4895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            6           ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 1)            3           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 1)            3           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z (Lambda)                     (None, 1)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "# use the reparameterization trick and get the output from the sample() function\n",
    "z = Lambda(sample, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "encoder = Model(inputs, z, name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41ef6cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z_sampling (InputLayer)     [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 4         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = Dense(original_dim, activation='sigmoid')(x)\n",
    "# Instantiate the decoder model:\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "992e5b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full VAE model\n",
    "outputs = decoder(encoder(inputs))\n",
    "vae_model = Model(inputs, outputs, name='vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd49851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the KL loss function:\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    # compute the average MSE error, then scale it up, ie. simply sum on all axes\n",
    "    reconstruction_loss = K.sum(K.square(x - x_decoded_mean))\n",
    "    # compute the KL loss\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.square(K.exp(z_log_var)), axis=-1)\n",
    "    # return the average loss over all \n",
    "    total_loss = K.mean(reconstruction_loss + kl_loss)    \n",
    "    #total_loss = reconstruction_loss + kl_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bf1d6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 2)]               0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 1)                 12        \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22\n",
      "Trainable params: 22\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 176250 samples, validate on 44070 samples\n",
      "Epoch 1/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 21:18:02.814606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 21:18:02.832088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 21:18:02.832245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 21:18:02.832950: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-09 21:18:02.833738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 21:18:02.833897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 21:18:02.834037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 21:18:03.090403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 21:18:03.090580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 21:18:03.090790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 21:18:03.090904: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-06-09 21:18:03.090934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9761 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27392/176250 [===>..........................] - ETA: 5s - loss: 134.9818"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 21:18:03.640790: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176250/176250 [==============================] - 2s 12us/sample - loss: 129.8074 - val_loss: 80.7213\n",
      "Epoch 2/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 119.4954 - val_loss: 72.7098\n",
      "Epoch 3/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 112.2965 - val_loss: 66.3535\n",
      "Epoch 4/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 106.0945 - val_loss: 60.4702\n",
      "Epoch 5/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 100.2820 - val_loss: 54.9589\n",
      "Epoch 6/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 94.8301 - val_loss: 49.8074\n",
      "Epoch 7/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 89.7469 - val_loss: 45.0083\n",
      "Epoch 8/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 85.0104 - val_loss: 40.5550\n",
      "Epoch 9/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 80.6129 - val_loss: 36.4430\n",
      "Epoch 10/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 76.5631 - val_loss: 32.6635\n",
      "Epoch 11/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 72.8202 - val_loss: 29.2077\n",
      "Epoch 12/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 69.4293 - val_loss: 26.0700\n",
      "Epoch 13/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 66.3429 - val_loss: 23.2838\n",
      "Epoch 14/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 63.5473 - val_loss: 20.9099\n",
      "Epoch 15/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 60.9987 - val_loss: 18.8874\n",
      "Epoch 16/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 58.6342 - val_loss: 17.1005\n",
      "Epoch 17/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 56.4507 - val_loss: 15.5095\n",
      "Epoch 18/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 54.4250 - val_loss: 14.0716\n",
      "Epoch 19/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 52.5364 - val_loss: 12.7407\n",
      "Epoch 20/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 50.7943 - val_loss: 11.5446\n",
      "Epoch 21/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 49.1890 - val_loss: 10.4677\n",
      "Epoch 22/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 47.7084 - val_loss: 9.4802\n",
      "Epoch 23/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 46.3402 - val_loss: 8.5918\n",
      "Epoch 24/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 45.0865 - val_loss: 7.7862\n",
      "Epoch 25/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 43.9264 - val_loss: 7.0698\n",
      "Epoch 26/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 42.8736 - val_loss: 6.4028\n",
      "Epoch 27/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 41.8970 - val_loss: 5.8183\n",
      "Epoch 28/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 41.0033 - val_loss: 5.2976\n",
      "Epoch 29/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 40.1845 - val_loss: 4.8418\n",
      "Epoch 30/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 39.4411 - val_loss: 4.4264\n",
      "Epoch 31/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 38.7570 - val_loss: 4.0493\n",
      "Epoch 32/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 38.1298 - val_loss: 3.7026\n",
      "Epoch 33/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 37.5608 - val_loss: 3.4127\n",
      "Epoch 34/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 37.0344 - val_loss: 3.1586\n",
      "Epoch 35/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 36.5532 - val_loss: 2.9271\n",
      "Epoch 36/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 36.1181 - val_loss: 2.7163\n",
      "Epoch 37/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 35.7138 - val_loss: 2.5377\n",
      "Epoch 38/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 35.3502 - val_loss: 2.3790\n",
      "Epoch 39/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 35.0199 - val_loss: 2.2404\n",
      "Epoch 40/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 34.7056 - val_loss: 2.1144\n",
      "Epoch 41/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 34.4344 - val_loss: 1.9996\n",
      "Epoch 42/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 34.1726 - val_loss: 1.9117\n",
      "Epoch 43/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 33.9313 - val_loss: 1.8138\n",
      "Epoch 44/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 33.7167 - val_loss: 1.7472\n",
      "Epoch 45/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 33.5173 - val_loss: 1.6644\n",
      "Epoch 46/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 33.3360 - val_loss: 1.6113\n",
      "Epoch 47/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 33.1727 - val_loss: 1.5670\n",
      "Epoch 48/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 33.0150 - val_loss: 1.5131\n",
      "Epoch 49/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 32.8717 - val_loss: 1.4838\n",
      "Epoch 50/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 32.7364 - val_loss: 1.4495\n",
      "Epoch 51/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 32.6220 - val_loss: 1.4101\n",
      "Epoch 52/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 32.5080 - val_loss: 1.3798\n",
      "Epoch 53/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 32.4147 - val_loss: 1.3550\n",
      "Epoch 54/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 32.3247 - val_loss: 1.3394\n",
      "Epoch 55/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 32.2325 - val_loss: 1.3296\n",
      "Epoch 56/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 32.1484 - val_loss: 1.3006\n",
      "Epoch 57/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 32.0721 - val_loss: 1.2998\n",
      "Epoch 58/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 32.0101 - val_loss: 1.2834\n",
      "Epoch 59/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.9482 - val_loss: 1.2706\n",
      "Epoch 60/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.8898 - val_loss: 1.2601\n",
      "Epoch 61/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.8355 - val_loss: 1.2509\n",
      "Epoch 62/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.7891 - val_loss: 1.2351\n",
      "Epoch 63/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.7400 - val_loss: 1.2364\n",
      "Epoch 64/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.7031 - val_loss: 1.2328\n",
      "Epoch 65/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.6597 - val_loss: 1.2157\n",
      "Epoch 66/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.6185 - val_loss: 1.2246\n",
      "Epoch 67/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.5932 - val_loss: 1.2209\n",
      "Epoch 68/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.5524 - val_loss: 1.2106\n",
      "Epoch 69/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.5376 - val_loss: 1.2118\n",
      "Epoch 70/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.5075 - val_loss: 1.2157\n",
      "Epoch 71/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.4838 - val_loss: 1.1997\n",
      "Epoch 72/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.4700 - val_loss: 1.1984\n",
      "Epoch 73/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.4427 - val_loss: 1.2114\n",
      "Epoch 74/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.4218 - val_loss: 1.2198\n",
      "Epoch 75/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.4072 - val_loss: 1.2148\n",
      "Epoch 76/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.3889 - val_loss: 1.2163\n",
      "Epoch 77/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.3754 - val_loss: 1.2093\n",
      "Epoch 78/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.3627 - val_loss: 1.2115\n",
      "Epoch 79/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.3442 - val_loss: 1.2125\n",
      "Epoch 80/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.3365 - val_loss: 1.1995\n",
      "Epoch 81/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.3137 - val_loss: 1.2003\n",
      "Epoch 82/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.3079 - val_loss: 1.2041\n",
      "Epoch 83/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.2955 - val_loss: 1.1905\n",
      "Epoch 84/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.2912 - val_loss: 1.1974\n",
      "Epoch 85/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.2836 - val_loss: 1.2029\n",
      "Epoch 86/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.2757 - val_loss: 1.2015\n",
      "Epoch 87/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 31.2628 - val_loss: 1.1896\n",
      "Epoch 88/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 31.2570 - val_loss: 1.1904\n",
      "Epoch 89/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.2510 - val_loss: 1.1858\n",
      "Epoch 90/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.2433 - val_loss: 1.2026\n",
      "Epoch 91/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.2323 - val_loss: 1.2042\n",
      "Epoch 92/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.2303 - val_loss: 1.2014\n",
      "Epoch 93/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.2219 - val_loss: 1.1968\n",
      "Epoch 94/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.2219 - val_loss: 1.1942\n",
      "Epoch 95/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.2091 - val_loss: 1.2047\n",
      "Epoch 96/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.2089 - val_loss: 1.1994\n",
      "Epoch 97/128\n",
      "176250/176250 [==============================] - 1s 5us/sample - loss: 31.2051 - val_loss: 1.2008\n",
      "Epoch 98/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1973 - val_loss: 1.1930\n",
      "Epoch 99/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1960 - val_loss: 1.1918\n",
      "Epoch 100/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 31.1923 - val_loss: 1.1946\n",
      "Epoch 101/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 31.1933 - val_loss: 1.1972\n",
      "Epoch 102/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 31.1875 - val_loss: 1.2011\n",
      "Epoch 103/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1888 - val_loss: 1.2060\n",
      "Epoch 104/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1759 - val_loss: 1.1974\n",
      "Epoch 105/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1747 - val_loss: 1.2034\n",
      "Epoch 106/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1706 - val_loss: 1.2061\n",
      "Epoch 107/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1698 - val_loss: 1.1895\n",
      "Epoch 108/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1711 - val_loss: 1.2037\n",
      "Epoch 109/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1651 - val_loss: 1.1951\n",
      "Epoch 110/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 31.1671 - val_loss: 1.1977\n",
      "Epoch 111/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1644 - val_loss: 1.1911\n",
      "Epoch 112/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1642 - val_loss: 1.1889\n",
      "Epoch 113/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1596 - val_loss: 1.1884\n",
      "Epoch 114/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1616 - val_loss: 1.1917\n",
      "Epoch 115/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1592 - val_loss: 1.1943\n",
      "Epoch 116/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1585 - val_loss: 1.2036\n",
      "Epoch 117/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1568 - val_loss: 1.1964\n",
      "Epoch 118/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1473 - val_loss: 1.1996\n",
      "Epoch 119/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1538 - val_loss: 1.2012\n",
      "Epoch 120/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1511 - val_loss: 1.2051\n",
      "Epoch 121/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1434 - val_loss: 1.1990\n",
      "Epoch 122/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1459 - val_loss: 1.1950\n",
      "Epoch 123/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1513 - val_loss: 1.1883\n",
      "Epoch 124/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 31.1479 - val_loss: 1.1930\n",
      "Epoch 125/128\n",
      "176250/176250 [==============================] - 1s 7us/sample - loss: 31.1451 - val_loss: 1.2024\n",
      "Epoch 126/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1460 - val_loss: 1.2016\n",
      "Epoch 127/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1516 - val_loss: 1.1989\n",
      "Epoch 128/128\n",
      "176250/176250 [==============================] - 1s 6us/sample - loss: 31.1439 - val_loss: 1.2146\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam(learning_rate=0.0001, clipvalue=0.5)\n",
    "#opt = optimizers.RMSprop(learning_rate=0.0001)\n",
    "\n",
    "vae_model.compile(optimizer=opt, loss=vae_loss)\n",
    "vae_model.summary()\n",
    "# Finally, we train the model:\n",
    "results = vae_model.fit(x_train, x_train,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(x_test, x_test),\n",
    "                        epochs=128,\n",
    "                        batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6e1e445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['NanumGothic'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['NanumGothic'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c53d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pred = vae_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d026526c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg error 0.06100279004266806\n",
      "median error 0.002329527643844159\n",
      "dataset: 0.7617207553118484\n",
      "setting threshold on 0.7617207553118484 \n"
     ]
    }
   ],
   "source": [
    "mae_vector = get_error(x_train_pred, x_train, _rmse=False)\n",
    "print(f'Avg error {np.mean(mae_vector)}\\nmedian error {np.median(mae_vector)}\\ndataset: {np.quantile(mae_vector, 0.99)}')\n",
    "print(f'setting threshold on { np.quantile(mae_vector, 0.99)} ')\n",
    "\n",
    "error_thresh = np.quantile(mae_vector, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c01edc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred = vae_model.predict(x_test)\n",
    "mae_vector = get_error(x_pred, x_test, _rmse=False)\n",
    "anomalies = (mae_vector > error_thresh)\n",
    "\n",
    "np.count_nonzero(anomalies) / len(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c18b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     44063\n",
      "         1.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           1.00     44070\n",
      "   macro avg       0.50      0.50      0.50     44070\n",
      "weighted avg       1.00      1.00      1.00     44070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540dea3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77958797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f7477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf022766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f827beff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432376f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f143ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f0aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a0301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b33547b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae831554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f5c7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51625a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c3f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torch_cuda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5f8954eb743e51db8344fe208b8d668e4e15c8eb1d37245f60cfcee664c52c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
