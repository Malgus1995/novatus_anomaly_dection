{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 / 데이터 불러오기\n",
    "\n",
    "## 1-1. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5625/3698489907.py:19: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:31:23.898915Z",
     "start_time": "2020-12-18T09:31:23.720877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>operation</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>month_categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.792242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sensor_04  operation  month  day  month_categorical\n",
       "0   0.792242        0.0      4    1                  2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_date(df):\n",
    "    df.split('-')[1]\n",
    "    df.split('-')[2].split(' ')[0]\n",
    "    return df.split('-')[1]+df.split('-')[2].split(' ')[0]\n",
    "df = pd.read_csv(r'/home/kym/ML/input/ai_nova/sensor04_pre_sensor.csv')\n",
    "df['timestamp'] = df['timestamp'].apply(extract_date)\n",
    "df = df.drop('Unnamed: 0',axis=1)\n",
    "def ReLU(x):\n",
    "    return x * (x > 0)\n",
    "def extract_month(df):\n",
    "    return int(df[0:2])\n",
    "def extract_day(df):\n",
    "    return int(df[2:])\n",
    "df['month'] = df['timestamp'].apply(extract_month)\n",
    "df['day'] = df['timestamp'].apply(extract_day)\n",
    "df = df.drop('timestamp',axis=1)\n",
    "def convert_month_to_categorical(df):\n",
    "    if df < 3:\n",
    "        return 1\n",
    "    elif 3<=df and df <6:\n",
    "        return 2\n",
    "    elif 6<=df and df <9:\n",
    "        return 3     \n",
    "    else:\n",
    "        return 4     \n",
    "df['month_categorical'] = df['month'].apply(convert_month_to_categorical)\n",
    "def label_manage(label):\n",
    "    if label==0.5: \n",
    "        return 1 # 0 or 1 \n",
    "    else:\n",
    "        return label\n",
    "df['operation']= df['operation'].apply(label_manage)\n",
    "\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>operation</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>month_categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>220320.000000</td>\n",
       "      <td>220320.000000</td>\n",
       "      <td>220320.000000</td>\n",
       "      <td>220320.000000</td>\n",
       "      <td>220320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.737412</td>\n",
       "      <td>0.065741</td>\n",
       "      <td>6.013072</td>\n",
       "      <td>15.803922</td>\n",
       "      <td>2.601307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.180685</td>\n",
       "      <td>0.247829</td>\n",
       "      <td>1.414156</td>\n",
       "      <td>8.835524</td>\n",
       "      <td>0.489630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.782515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.790064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.796307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sensor_04      operation          month            day  \\\n",
       "count  220320.000000  220320.000000  220320.000000  220320.000000   \n",
       "mean        0.737412       0.065741       6.013072      15.803922   \n",
       "std         0.180685       0.247829       1.414156       8.835524   \n",
       "min         0.000000       0.000000       4.000000       1.000000   \n",
       "25%         0.782515       0.000000       5.000000       8.000000   \n",
       "50%         0.790064       0.000000       6.000000      16.000000   \n",
       "75%         0.796307       0.000000       7.000000      23.000000   \n",
       "max         1.000000       1.000000       8.000000      31.000000   \n",
       "\n",
       "       month_categorical  \n",
       "count      220320.000000  \n",
       "mean            2.601307  \n",
       "std             0.489630  \n",
       "min             2.000000  \n",
       "25%             2.000000  \n",
       "50%             3.000000  \n",
       "75%             3.000000  \n",
       "max             3.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_0afe5_row0_col0,#T_0afe5_row1_col1,#T_0afe5_row2_col2,#T_0afe5_row3_col3,#T_0afe5_row4_col4{\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_0afe5_row0_col1,#T_0afe5_row0_col4,#T_0afe5_row1_col0,#T_0afe5_row1_col2,#T_0afe5_row1_col3,#T_0afe5_row1_col4{\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_0afe5_row0_col2{\n",
       "            background-color:  #5f7fe8;\n",
       "            color:  #000000;\n",
       "        }#T_0afe5_row0_col3{\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_0afe5_row2_col0{\n",
       "            background-color:  #e0dbd8;\n",
       "            color:  #000000;\n",
       "        }#T_0afe5_row2_col1{\n",
       "            background-color:  #cedaeb;\n",
       "            color:  #000000;\n",
       "        }#T_0afe5_row2_col3{\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_0afe5_row2_col4{\n",
       "            background-color:  #df634e;\n",
       "            color:  #000000;\n",
       "        }#T_0afe5_row3_col0{\n",
       "            background-color:  #dadce0;\n",
       "            color:  #000000;\n",
       "        }#T_0afe5_row3_col1{\n",
       "            background-color:  #d3dbe7;\n",
       "            color:  #000000;\n",
       "        }#T_0afe5_row3_col2{\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }#T_0afe5_row3_col4{\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_0afe5_row4_col0,#T_0afe5_row4_col1{\n",
       "            background-color:  #d6dce4;\n",
       "            color:  #000000;\n",
       "        }#T_0afe5_row4_col2{\n",
       "            background-color:  #de614d;\n",
       "            color:  #000000;\n",
       "        }#T_0afe5_row4_col3{\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_0afe5_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >sensor_04</th>        <th class=\"col_heading level0 col1\" >operation</th>        <th class=\"col_heading level0 col2\" >month</th>        <th class=\"col_heading level0 col3\" >day</th>        <th class=\"col_heading level0 col4\" >month_categorical</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_0afe5_level0_row0\" class=\"row_heading level0 row0\" >sensor_04</th>\n",
       "                        <td id=\"T_0afe5_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_0afe5_row0_col1\" class=\"data row0 col1\" >-0.916251</td>\n",
       "                        <td id=\"T_0afe5_row0_col2\" class=\"data row0 col2\" >0.066421</td>\n",
       "                        <td id=\"T_0afe5_row0_col3\" class=\"data row0 col3\" >0.021166</td>\n",
       "                        <td id=\"T_0afe5_row0_col4\" class=\"data row0 col4\" >-0.004105</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0afe5_level0_row1\" class=\"row_heading level0 row1\" >operation</th>\n",
       "                        <td id=\"T_0afe5_row1_col0\" class=\"data row1 col0\" >-0.916251</td>\n",
       "                        <td id=\"T_0afe5_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_0afe5_row1_col2\" class=\"data row1 col2\" >-0.061016</td>\n",
       "                        <td id=\"T_0afe5_row1_col3\" class=\"data row1 col3\" >-0.031374</td>\n",
       "                        <td id=\"T_0afe5_row1_col4\" class=\"data row1 col4\" >-0.007493</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0afe5_level0_row2\" class=\"row_heading level0 row2\" >month</th>\n",
       "                        <td id=\"T_0afe5_row2_col0\" class=\"data row2 col0\" >0.066421</td>\n",
       "                        <td id=\"T_0afe5_row2_col1\" class=\"data row2 col1\" >-0.061016</td>\n",
       "                        <td id=\"T_0afe5_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "                        <td id=\"T_0afe5_row2_col3\" class=\"data row2 col3\" >0.015898</td>\n",
       "                        <td id=\"T_0afe5_row2_col4\" class=\"data row2 col4\" >0.866513</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0afe5_level0_row3\" class=\"row_heading level0 row3\" >day</th>\n",
       "                        <td id=\"T_0afe5_row3_col0\" class=\"data row3 col0\" >0.021166</td>\n",
       "                        <td id=\"T_0afe5_row3_col1\" class=\"data row3 col1\" >-0.031374</td>\n",
       "                        <td id=\"T_0afe5_row3_col2\" class=\"data row3 col2\" >0.015898</td>\n",
       "                        <td id=\"T_0afe5_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "                        <td id=\"T_0afe5_row3_col4\" class=\"data row3 col4\" >0.004592</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0afe5_level0_row4\" class=\"row_heading level0 row4\" >month_categorical</th>\n",
       "                        <td id=\"T_0afe5_row4_col0\" class=\"data row4 col0\" >-0.004105</td>\n",
       "                        <td id=\"T_0afe5_row4_col1\" class=\"data row4 col1\" >-0.007493</td>\n",
       "                        <td id=\"T_0afe5_row4_col2\" class=\"data row4 col2\" >0.866513</td>\n",
       "                        <td id=\"T_0afe5_row4_col3\" class=\"data row4 col3\" >0.004592</td>\n",
       "                        <td id=\"T_0afe5_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f93343d5400>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('month',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_39f6a_row0_col0,#T_39f6a_row1_col1,#T_39f6a_row2_col2,#T_39f6a_row3_col3{\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_39f6a_row0_col1,#T_39f6a_row0_col3,#T_39f6a_row1_col0,#T_39f6a_row1_col2,#T_39f6a_row1_col3{\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_39f6a_row0_col2{\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_39f6a_row2_col0{\n",
       "            background-color:  #dadce0;\n",
       "            color:  #000000;\n",
       "        }#T_39f6a_row2_col1{\n",
       "            background-color:  #d3dbe7;\n",
       "            color:  #000000;\n",
       "        }#T_39f6a_row2_col3{\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_39f6a_row3_col0,#T_39f6a_row3_col1{\n",
       "            background-color:  #d6dce4;\n",
       "            color:  #000000;\n",
       "        }#T_39f6a_row3_col2{\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_39f6a_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >sensor_04</th>        <th class=\"col_heading level0 col1\" >operation</th>        <th class=\"col_heading level0 col2\" >day</th>        <th class=\"col_heading level0 col3\" >month_categorical</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_39f6a_level0_row0\" class=\"row_heading level0 row0\" >sensor_04</th>\n",
       "                        <td id=\"T_39f6a_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_39f6a_row0_col1\" class=\"data row0 col1\" >-0.916251</td>\n",
       "                        <td id=\"T_39f6a_row0_col2\" class=\"data row0 col2\" >0.021166</td>\n",
       "                        <td id=\"T_39f6a_row0_col3\" class=\"data row0 col3\" >-0.004105</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_39f6a_level0_row1\" class=\"row_heading level0 row1\" >operation</th>\n",
       "                        <td id=\"T_39f6a_row1_col0\" class=\"data row1 col0\" >-0.916251</td>\n",
       "                        <td id=\"T_39f6a_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_39f6a_row1_col2\" class=\"data row1 col2\" >-0.031374</td>\n",
       "                        <td id=\"T_39f6a_row1_col3\" class=\"data row1 col3\" >-0.007493</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_39f6a_level0_row2\" class=\"row_heading level0 row2\" >day</th>\n",
       "                        <td id=\"T_39f6a_row2_col0\" class=\"data row2 col0\" >0.021166</td>\n",
       "                        <td id=\"T_39f6a_row2_col1\" class=\"data row2 col1\" >-0.031374</td>\n",
       "                        <td id=\"T_39f6a_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "                        <td id=\"T_39f6a_row2_col3\" class=\"data row2 col3\" >0.004592</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_39f6a_level0_row3\" class=\"row_heading level0 row3\" >month_categorical</th>\n",
       "                        <td id=\"T_39f6a_row3_col0\" class=\"data row3 col0\" >-0.004105</td>\n",
       "                        <td id=\"T_39f6a_row3_col1\" class=\"data row3 col1\" >-0.007493</td>\n",
       "                        <td id=\"T_39f6a_row3_col2\" class=\"data row3 col2\" >0.004592</td>\n",
       "                        <td id=\"T_39f6a_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9336a4aa00>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:32:04.919875Z",
     "start_time": "2020-12-18T09:32:04.913876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220320, 3) (220320,)\n"
     ]
    }
   ],
   "source": [
    " # 측정데이터와 레이블(정답)을 분리\n",
    "X = df.drop('operation',axis=1)\n",
    "y = df['operation']\n",
    "# print(y[-1:].reshape(-1))   # iloc으로 받아오면 numpy의 ndarray형이다.\n",
    "#y = np.where(y == 'operation', 1, 0)\n",
    "#y = y.ravel()   # 레이블을 1차원으로 변경하자.\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "         ... \n",
       "220315    0.0\n",
       "220316    0.0\n",
       "220317    0.0\n",
       "220318    0.0\n",
       "220319    0.0\n",
       "Name: operation, Length: 220320, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:32:06.612874Z",
     "start_time": "2020-12-18T09:32:06.608889Z"
    }
   },
   "outputs": [],
   "source": [
    "# 훈련셋과 테스트셋 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 결과 분석 및 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:33:12.888877Z",
     "start_time": "2020-12-18T09:33:12.873889Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test=None, pred=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test,pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도 :{0: .4f}, 정밀도: {1: .4f}, 재현율: {2: .4f}, F1 : {3: .4f}'.format(accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cls = RandomForestClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cls = rf_cls.fit(X_train, y_train)\n",
    "rf_prediction = rf_cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[61352   452]\n",
      " [   92  4200]]\n",
      "정확도 : 0.9918, 정밀도:  0.9028, 재현율:  0.9786, F1 :  0.9392\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, rf_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176299    0.0\n",
       "31719     0.0\n",
       "37626     0.0\n",
       "155023    0.0\n",
       "140065    0.0\n",
       "         ... \n",
       "177841    0.0\n",
       "103024    0.0\n",
       "147629    0.0\n",
       "1244      0.0\n",
       "86909     0.0\n",
       "Name: operation, Length: 154224, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/pandas/core/indexes/base.py:3080\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3081\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:101\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:1625\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:1632\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m vae_x_tr \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xi, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(np\u001b[38;5;241m.\u001b[39masarray(X_train)):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      4\u001b[0m         vae_x_tr\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m      6\u001b[0m vae_x_test \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/pandas/core/series.py:853\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/pandas/core/series.py:961\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m    960\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m--> 961\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/pandas/core/indexes/base.py:3082\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3081\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3082\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tolerance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     tolerance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_tolerance(tolerance, np\u001b[38;5;241m.\u001b[39masarray(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "vae_x_tr = []\n",
    "for xi, x in enumerate(np.asarray(X_train)):\n",
    "    if y_train[xi] == 1:\n",
    "        vae_x_tr.append(x)\n",
    "        \n",
    "vae_x_test = []\n",
    "for xi, x in enumerate(np.asarray(X_test)):\n",
    "    if y_test[xi] == 0:\n",
    "        vae_x_test.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vae_x_train = df.loc[df['INSP']=='OK'].iloc[:, 1:5].values\n",
    "vae_x_train = np.asarray(vae_x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      2, ..., 154221, 154222, 154223])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_train==0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176299    0.0\n",
       "31719     0.0\n",
       "37626     0.0\n",
       "155023    0.0\n",
       "140065    0.0\n",
       "         ... \n",
       "177841    0.0\n",
       "103024    0.0\n",
       "147629    0.0\n",
       "1244      0.0\n",
       "86909     0.0\n",
       "Name: operation, Length: 154224, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_x_tr = []\n",
    "vae_x_vaild = []\n",
    "vae_x_test= []\n",
    "arr_x_train = np.asarray(X_train)\n",
    "arr_y_train = np.asarray(y_train)\n",
    "for indice in np.where(y_train==0)[0]:\n",
    "    vae_x_tr.append(arr_x_train[indice])\n",
    "    \n",
    "for indice in np.where(y_train==1)[0]:\n",
    "    vae_x_vaild.append(arr_x_train[indice])\n",
    "\n",
    "vae_x_train = np.asarray(vae_x_tr)\n",
    "vae_x_vaild = np.asarray(vae_x_vaild)\n",
    "\n",
    "vae_x_test = np.asarray(X_test)\n",
    "vae_y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size =len(vae_x_train[0]) \n",
    "hidden_size = [8,64,256]\n",
    "output_size =2\n",
    "batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AutoEncoder 클래스 구현 \n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "        ## initialize\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.Relu = nn.RReLU()\n",
    "        ##오토인코더 구현\n",
    "        \n",
    "        self.fc_mu = nn.Linear(output_size,output_size)\n",
    "        self.fc_var =nn.Linear(output_size,output_size)\n",
    "        \n",
    "        ## 인코더 부분\n",
    "        self.input_en_layer = nn.Linear(input_size, hidden_size[0])\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size[0])\n",
    "        self.input_en_layer_2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size[1])\n",
    "        self.input_en_layer_3 = nn.Linear(hidden_size[1], hidden_size[2])\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_size[2])\n",
    "        self.output_en_layer = nn.Linear(hidden_size[2], output_size)\n",
    "        \n",
    "        #log_var = \n",
    "        \n",
    "        ## 디코더 부분\n",
    "        self.input_dic_layer = nn.Linear(output_size, hidden_size[2])\n",
    "        self.input_dic_layer_3 = nn.Linear(hidden_size[2], hidden_size[1])\n",
    "        self.input_dic_layer_2 = nn.Linear(hidden_size[1], hidden_size[0])\n",
    "        \n",
    "        self.output_dic_layer = nn.Linear(hidden_size[0], input_size)\n",
    "        \n",
    "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "        self.mu = 0\n",
    "        self.z = 0\n",
    "        self.log_var = 0\n",
    "        \n",
    "        \n",
    "    def encode(self,inputs):\n",
    "        x = self.bn1(self.input_en_layer(inputs))\n",
    "        x = self.Relu(x)\n",
    "        \n",
    "        x = self.bn2(self.input_en_layer_2(x))\n",
    "        x = self.Relu(x)\n",
    "        x = self.bn3(self.input_en_layer_3(x))\n",
    "        x = self.Relu(x)\n",
    "\n",
    "        output = self.output_en_layer(x) \n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def decode(self,output):\n",
    "        output = self.input_dic_layer(output)\n",
    "        output = self.Relu(output)\n",
    "        output = (self.input_dic_layer_3(output))\n",
    "        output = self.Relu(output)\n",
    "        output = (self.input_dic_layer_2(output))\n",
    "        output = self.Relu(output)\n",
    "        output = self.output_dic_layer(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def gaussian_likelihood(self,x_hat,x):\n",
    "        scale=  torch.exp(torch.tensor(self.log_scale))\n",
    "        mean = x_hat\n",
    "        dist = torch.distributions.Normal(mean,scale)\n",
    "        \n",
    "        log_pxz = dist.log_prob(x)\n",
    "        \n",
    "        return log_pxz.sum(dim=(1))\n",
    "        \n",
    " \n",
    "    def kl_divergence(self, z, mu, std):\n",
    "        # --------------------------\n",
    "        # Monte carlo KL divergence\n",
    "        # --------------------------\n",
    "        # 1. define the first two probabilities (in this case Normal for both)\n",
    "        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "\n",
    "        # 2. get the probabilities from the equation\n",
    "        log_qzx = q.log_prob(z)\n",
    "        log_pz = p.log_prob(z)\n",
    "\n",
    "        # kl\n",
    "        kl = (log_qzx - log_pz)\n",
    "\n",
    "        # sum over last dim to go from single dim distribution to multi-dim\n",
    "        kl = kl.sum(-1)\n",
    "        return kl\n",
    "    \n",
    "    \n",
    "    def forward(self, inputs): \n",
    "        output = self.encode(inputs)\n",
    "        self.mu = self.fc_mu(output)\n",
    "        self.log_var = self.fc_var(output)\n",
    "        std = torch.exp(self.log_var/2)\n",
    "        q = torch.distributions.Normal(self.mu,std)\n",
    "        z = q.rsample()\n",
    "        x_hat = self.decode(z)\n",
    "        \n",
    "        recon_loss = self.gaussian_likelihood(x_hat,inputs)\n",
    "        kl =  self.kl_divergence(z,self.mu,std)\n",
    "        \n",
    "        elbo = (kl - recon_loss)\n",
    "        elbo = elbo.mean()\n",
    "        \n",
    "        return elbo\n",
    "\n",
    "    def predict(self, inputs): \n",
    "        output = self.encode(inputs)\n",
    "        self.mu = self.fc_mu(output)\n",
    "        self.log_var = self.fc_var(output)\n",
    "        std = torch.exp(self.log_var/2)\n",
    "        q = torch.distributions.Normal(self.mu,std)\n",
    "        z = q.rsample()\n",
    "        x_hat = self.decode(z)\n",
    "        \n",
    "        recon_loss = self.gaussian_likelihood(x_hat,inputs)\n",
    "        kl =  self.kl_divergence(z,self.mu,std)\n",
    "        \n",
    "        elbo = (kl - recon_loss)\n",
    "\n",
    "        \n",
    "        return elbo\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSELoss = nn.MSELoss()\n",
    "## 매개변수 조정 방식으로 Adam사용\n",
    "optimizer = torch.optim.Adam\n",
    "VAE = VariationalAutoEncoder(input_size,hidden_size, output_size)\n",
    "optim = optimizer(VAE.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5625/1895833182.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x,dtype=torch.float32)\n",
      "/tmp/ipykernel_5625/2297523557.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scale=  torch.exp(torch.tensor(self.log_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 3183.44\n",
      "epoch: 20, loss: 3168.51\n",
      "epoch: 30, loss: 3141.83\n",
      "epoch: 40, loss: 3127.30\n",
      "epoch: 50, loss: 3129.86\n",
      "epoch: 60, loss: 3119.25\n",
      "epoch: 70, loss: 3109.64\n",
      "epoch: 80, loss: 3109.84\n",
      "epoch: 90, loss: 3097.60\n",
      "epoch: 100, loss: 3098.40\n"
     ]
    }
   ],
   "source": [
    "Adam = optimizer(VAE.parameters(), lr =0.001,weight_decay=0.00005)\n",
    "## 배치 학습을 시키기 위한 데이터 변환\n",
    "data_iter = DataLoader(vae_x_train, batch_size =batch_size, shuffle =True)\n",
    "## 에포크 학습\n",
    "vae_train_loss =[]\n",
    "VAE.train()\n",
    "for ep in range(1, 100 +1):\n",
    "    running_loss =0.0\n",
    "    for x in data_iter:\n",
    "        ## 매개변수 0으로 초기화\n",
    "        Adam.zero_grad()\n",
    "        x = torch.tensor(x,dtype=torch.float32)\n",
    "        loss = VAE.forward(x)\n",
    "        #loss += MSELoss(output,x)\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        Adam.step()\n",
    "        running_loss += loss.item()\n",
    "    vae_train_loss.append(running_loss/batch_size)\n",
    "    ## 각 에포크마다 손실 값 표기\n",
    "    if ep%10==0:\n",
    "        print(\"epoch: {}, loss: {:.2f}\".format(ep, running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f93301d8d90>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['NanumGothic'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('VAE')\n",
    "plt.plot(vae_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VariationalAutoEncoder(\n",
       "  (Relu): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "  (fc_mu): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (fc_var): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (input_en_layer): Linear(in_features=3, out_features=8, bias=True)\n",
       "  (bn1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (input_en_layer_2): Linear(in_features=8, out_features=64, bias=True)\n",
       "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (input_en_layer_3): Linear(in_features=64, out_features=256, bias=True)\n",
       "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (output_en_layer): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (input_dic_layer): Linear(in_features=2, out_features=256, bias=True)\n",
       "  (input_dic_layer_3): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (input_dic_layer_2): Linear(in_features=64, out_features=8, bias=True)\n",
       "  (output_dic_layer): Linear(in_features=8, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAE.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5625/2297523557.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scale=  torch.exp(torch.tensor(self.log_scale))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5.5710, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAE.forward(torch.tensor(vae_x_train[0:1],dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5625/4068705557.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(data,dtype=torch.float32)\n",
      "/tmp/ipykernel_5625/2297523557.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scale=  torch.exp(torch.tensor(self.log_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold : 5.65755556227338\n"
     ]
    }
   ],
   "source": [
    "## 훈련세트의 손실값 이용한 임계값 정의\n",
    "train_loss_chart = []\n",
    "test_iter = DataLoader(vae_x_train, batch_size =batch_size, shuffle =True)\n",
    "for data in test_iter:\n",
    "    data = torch.tensor(data,dtype=torch.float32)\n",
    "    loss = VAE.forward(data)\n",
    "    #loss += MSELoss(output,data)\n",
    "    train_loss_chart.append(loss.item())\n",
    "    \n",
    "threshold = np.mean(train_loss_chart) + np.std(train_loss_chart)*10\n",
    "print(\"Threshold :\", threshold)  #결과는 아래에서 확인 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5625/3268712293.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(data,dtype=torch.float32)\n",
      "/tmp/ipykernel_5625/2297523557.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scale=  torch.exp(torch.tensor(self.log_scale))\n"
     ]
    }
   ],
   "source": [
    "## 훈련세트의 손실값 이용한 임계값 정의\n",
    "test_loss_chart = []\n",
    "test_iter = DataLoader(vae_x_test, batch_size =batch_size)\n",
    "y_pred = []\n",
    "for data in test_iter:\n",
    "    #data = (torch.unsqueeze(data,0))\n",
    "    data = torch.tensor(data,dtype=torch.float32)\n",
    "    #print(data.shape)\n",
    "    loss = VAE.predict(data)\n",
    "    #loss += MSELoss(output,data)\n",
    "    for pred_loss in loss:\n",
    "        pred = 0\n",
    "        if pred_loss >threshold:\n",
    "            pred = 1     \n",
    "        y_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8284011135318324"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3258440323347599"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2537      0.0\n",
       "168862    0.0\n",
       "130862    1.0\n",
       "105410    0.0\n",
       "218003    0.0\n",
       "         ... \n",
       "103142    0.0\n",
       "1650      0.0\n",
       "170925    0.0\n",
       "56347     0.0\n",
       "114430    0.0\n",
       "Name: operation, Length: 66096, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "a5f8954eb743e51db8344fe208b8d668e4e15c8eb1d37245f60cfcee664c52c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
